{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fitz  \n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering, pipeline\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import urllib3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "config = json.load(open('config.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elasticsearch Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:397: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/tmp/ipykernel_51694/4189873407.py:1: DeprecationWarning: The 'http_auth' parameter is deprecated. Use 'basic_auth' or 'bearer_auth' parameters instead\n",
      "  es = Elasticsearch(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch cluster is up!\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch(\n",
    "    hosts=[{\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": 9200,\n",
    "        \"scheme\": \"https\"  # This should be included here as part of the host dictionary\n",
    "    }],\n",
    "    http_auth=(\"elastic\", \"BUzQ9CnGPb-lHUxtotuA\"),  # Use your username and password\n",
    "    verify_certs=False  # Disable SSL certificate verification (for self-signed certs)\n",
    ")\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    if es.ping():\n",
    "        print(\"Elasticsearch cluster is up!\")\n",
    "    else:\n",
    "        print(\"Elasticsearch cluster is down!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Elasticsearch: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadApiResponse(True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.exists(index=\"pdf_text_chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.abspath(os.path.join(dirpath, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_paths = absoluteFilePaths('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch(['https://localhost:9200'])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Storage and Retrieval\n",
    "embedder_model = AutoModel.from_pretrained(config['MODEL']['embedder_model'])\n",
    "embedder_tokenizer = AutoTokenizer.from_pretrained(config['MODEL']['embedder_model'])\n",
    "\n",
    "\n",
    "# qa_tokenizer = AutoTokenizer.from_pretrained(config['MODEL']['qa_pipeline_model'])\n",
    "# qa_model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "#         config['MODEL']['qa_pipeline_model'],\n",
    "#         torch_dtype=torch.float32,  # Use half precision\n",
    "#         low_cpu_mem_usage=True\n",
    "#     )\n",
    "qa_pipeline = pipeline(\n",
    "        \"question-answering\",\n",
    "        model=config['MODEL']['qa_pipeline_model'],\n",
    "        tokenizer=config['MODEL']['qa_pipeline_model']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "import torch\n",
    "\n",
    "\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": config['MODEL']['embedding_dim']} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# es.indices.create(index=\"pdf_text_chunks\", body=index_mapping)\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from each page in a PDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text_data = []\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text_data.append(page.get_text(\"text\"))\n",
    "    return text_data\n",
    "\n",
    "def chunk_text(text, chunk_size=300):\n",
    "    \"\"\"Splits text into smaller chunks for embedding.\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "def embed_text(text):\n",
    "    \"\"\"Generate embeddings for a text chunk.\"\"\"\n",
    "    inputs = embedder_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    embeddings = embedder_model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    return embeddings.detach().numpy().tolist()[0]\n",
    "\n",
    "def index_text_chunks(text_chunks, doc_id):\n",
    "    \"\"\"Index text chunks in Elasticsearch with embeddings.\"\"\"\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": \"pdf_text_chunks\",\n",
    "            \"_id\": f\"{doc_id}_{i}\",\n",
    "            \"_source\": {\n",
    "                \"text\": chunk,\n",
    "                \"embedding\": embed_text(chunk)\n",
    "            }\n",
    "        }\n",
    "        for i, chunk in enumerate(text_chunks)\n",
    "    ]\n",
    "    bulk(es, actions)\n",
    "\n",
    "# Load PDFs and process\n",
    "\n",
    "# pdf_files = [\"path/to/pdf1.pdf\", \"path/to/pdf2.pdf\"]\n",
    "\n",
    "# for pdf_path in pdf_files:\n",
    "# for pdf_path in raw_data_paths:\n",
    "#     print(pdf_path)\n",
    "#     text_data = extract_text_from_pdf(pdf_path)\n",
    "#     for page_num, page_text in tqdm(enumerate(text_data)):\n",
    "#         chunks = chunk_text(page_text)\n",
    "#         index_text_chunks(chunks, doc_id=f\"{pdf_path}_page_{page_num}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for pdf_path in raw_data_paths:\n",
    "    print(pdf_path)\n",
    "    text_data = extract_text_from_pdf(pdf_path)\n",
    "    for page_num, page_text in tqdm(enumerate(text_data)):\n",
    "        chunks = chunk_text(page_text)\n",
    "        index_text_chunks(chunks, doc_id=f\"{pdf_path}_page_{page_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'pdf_text_chunks': {'mappings': {'properties': {'embedding': {'type': 'float'}, 'text': {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}}}}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.get_mapping(index='pdf_text_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=\"pdf_text_chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_chunks(question, top_k=3):\n",
    "    \"\"\"Retrieve top K most relevant chunks based on the question.\"\"\"\n",
    "    # Embed the question\n",
    "    question_embedding = embed_text(question)\n",
    "    query_body = {\n",
    "        \"size\": top_k,\n",
    "        \"_source\": [\"text\"],\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"match_all\": {}},\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                    \"params\": {\"query_vector\": question_embedding}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    res = es.search(index=\"pdf_text_chunks\", body=query_body)\n",
    "    return [hit[\"_source\"][\"text\"] for hit in res[\"hits\"][\"hits\"]]\n",
    "\n",
    "# def generate_answer(question, context):\n",
    "#     \"\"\"Generate answer based on context using a generative model.\"\"\"\n",
    "#     input_text = f\"Question: {question}\\nContext: {' '.join(context)}\"\n",
    "#     return qa_pipeline(input_text)[0][\"generated_text\"]\n",
    "\n",
    "def generate_answer(question, context):\n",
    "    \"\"\"Generate answer based on context using a generative model.\"\"\"\n",
    "    \n",
    "    context = ' '.join(context)\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "    \n",
    "# Main QA Function\n",
    "def answer_question(question):\n",
    "    context_chunks = retrieve_relevant_chunks(question)\n",
    "    for context_chunk in context_chunks:\n",
    "        print(f\"chunk : {context_chunk}\")\n",
    "    answer = generate_answer(question, context_chunks)\n",
    "    return answer\n",
    "\n",
    "# Example Usage\n",
    "# question = \"What are the key findings in the report?\"\n",
    "# print(\"Answer:\", answer_question(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are different types of leaves available to Simpplr employees ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51694/3663990730.py:18: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  res = es.search(index=\"pdf_text_chunks\", body=query_body)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk : Employee Stock Options Policy 1. Introduction 1.1 Purpose This policy outlines the guidelines and procedures for granting and managing employee stock options at Simpplr. The purpose is to provide employees with an additional incentive and reward for their loyalty, commitment, and contribution towards the growth and success of the organization. 1.2 Scope This policy applies to all full-time employees of Simpplr who meet the eligibility criteria and are selected to participate in the employee stock option program. 2. Eligibility 2.1 Criteria Employees who have completed a minimum of one year of continuous service with Simpplr and are in good standing are eligible to participate in the employee stock option program. 2.2 Participation Participation in the employee stock option program is voluntary, and eligible employees must indicate their interest within a specified deadline communicated by the Human Resources department. 3. Stock Option Granting 3.1 Granting Process The granting of stock options will be based on various factors such as employee performance, contribution to the company's objectives, and potential for future success. The grant of stock options will be approved by the executive management team and the Board of Directors. 3.2 Grant Schedule Stock options may be granted on an annual basis, during a specific time period, or as determined by the company's discretion. The specific number of options and the terms of each grant will be communicated to eligible employees at the time of the grant. 3.3 Vesting Schedule\n",
      "chunk : Title: Personal and Paid Leave Policy Introduction: At Simpplr, we prioritize the well-being and work-life balance of our employees. The Personal and Paid Leave Policy aims to create an inclusive and supportive work environment that allows employees to take time off for personal reasons, such as illness, family emergencies, or personal appointments, while ensuring they are compensated during their absence. This policy outlines the provisions and guidelines for personal and paid leaves, eligibility requirements, the application process, and the benefits employees can expect while on leave. Policy Statement: Simpplr acknowledges the importance of personal time and understands that employees may need to take time off for various personal reasons. This policy ensures that eligible employees have the opportunity to balance their personal and professional lives while maintaining job security and receiving payment for their approved leave. All full-time and part-time employees who have completed at least six months of continuous employment with Simpplr are eligible for personal and paid leaves. Types of Leave and Eligibility: 1. Personal Leave: a. Employees are eligible for personal leave to attend to their personal matters, including medical appointments, family emergencies, and personal obligations. b. Personal leave is granted up to a maximum of five days per year. c. Employees must provide reasonable notice to their supervisor and Human Resources, unless unforeseen circumstances prevent advance notice. 2. Paid Sick Leave: a. Employees are eligible for paid sick leave when they are unable to perform their duties due to their own illness or the illness of an immediate family member. b. Paid sick leave is granted for a maximum of 10 days per calendar year. c. Medical certification may be required based on the nature and duration of the illness. 3. Bereavement Leave: a. Employees are eligible for paid bereavement leave in the event of the\n",
      "chunk : parties as necessary. Any changes or updates to this policy will be communicated to all eligible employees in a timely manner. 7. Disclaimer This policy is not a contract of employment and does not guarantee any future grants or benefits. Simpplr reserves the right to modify, suspend, or terminate the employee stock option program or any individual grant at its sole discretion. Please note that the above policy is a general framework and should be customized to meet the specific needs and legal requirements of Simpplr. It is recommended to consult with legal counsel or experts in employee stock options while implementing the policy.\n",
      "Answer: Personal Leave\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", answer_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"When is an employee eligible for remote work at Simpplr ?\"\n",
    "# print(\"Answer:\", answer_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51694/3663990730.py:18: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  res = es.search(index=\"pdf_text_chunks\", body=query_body)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk : Title: Remote Work Policy Introduction: Simpplr recognizes the growing need for flexibility in the workplace and understands the benefits of remote work for both employees and the organization. The Remote Work Policy outlines the provisions and guidelines for employees who wish to work remotely, either on a full-time or ad-hoc basis. This policy aims to promote a healthy work-life balance, increase productivity, and create a positive work environment for our employees. Policy Statement: Simpplr is committed to providing employees with the opportunity to work remotely, subject to business needs and the nature of their roles. This policy applies to all eligible employees, regardless of their tenure or position within the organization. Remote work may be approved when it benefits both the employee and the company while maintaining the highest level of productivity and collaboration. Eligibility for Remote Work: 1. Employment Eligibility: a. All employees who have completed at least six months of continuous employment with Simpplr are eligible to request remote work. b. Employees should have a proven track record of performance and the ability to work independently. 2. Role Suitability: a. Employees must perform roles that can be effectively fulfilled remotely without negatively impacting productivity, collaboration, or customer service. b. Certain roles or positions may require on-site presence due to business needs or operational requirements. Remote Work Arrangements: 1. Full-Time Remote Work: a. Employees may request to work remotely on a full-time basis, subject to approval by their supervisor and the Human Resources department. b. Full-time remote work arrangements should be reviewed annually to assess their continued feasibility and the alignment of organizational goals. 2. Ad-Hoc Remote Work: a. Employees may request occasional ad-hoc remote work on a case-by-case basis. b. Ad-hoc remote work should be reasonable in duration, frequency, and should not exceed the pre-defined limits set by\n",
      "chunk : a. Remote employees are required to meet the same performance standards and expectations as on-site employees. b. Regular communication and collaboration with colleagues and supervisors are essential for remote employees to ensure productivity and engagement. 2. Availability and Accessibility: a. Remote employees must be accessible during regular business hours. b. Employees must have reliable internet access, suitable technology equipment, and maintain a professional work environment. 3. Work Schedule and Timekeeping: a. Remote employees should maintain a regular work schedule that aligns with their team and the organization. b. Accurate timekeeping and adherence to break and lunch schedules are necessary. 4. Confidentiality and Data Security: a. Remote employees must adhere to Simpplr's confidentiality and data security policies. b. Employees should safeguard company information, data, and intellectual property by following established security protocols. Conclusion: The Remote Work Policy at Simpplr aims to provide employees with the opportunity to work remotely, where feasible and business needs allow. By embracing remote work, we strive to create a flexible work environment that enhances work-life balance, promotes productivity, and fosters a positive employee experience. This policy outlines the eligibility criteria, guidelines, and expectations for remote work arrangements. Simpplr encourages open communication and collaboration to maintain effective remote work practices.\n",
      "chunk : parties as necessary. Any changes or updates to this policy will be communicated to all eligible employees in a timely manner. 7. Disclaimer This policy is not a contract of employment and does not guarantee any future grants or benefits. Simpplr reserves the right to modify, suspend, or terminate the employee stock option program or any individual grant at its sole discretion. Please note that the above policy is a general framework and should be customized to meet the specific needs and legal requirements of Simpplr. It is recommended to consult with legal counsel or experts in employee stock options while implementing the policy.\n",
      "Answer: where feasible and business needs allow\n"
     ]
    }
   ],
   "source": [
    "question = \"According to the company policy, answer the following question : When is an employee eligible for remote work at Simpplr ?\"\n",
    "print(\"Answer:\", answer_question(question))\n",
    "# answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.33.1'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
